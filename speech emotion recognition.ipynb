{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import utils \n",
    "import sklearn\n",
    "import re\n",
    "import numpy as np\n",
    "import librosa\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = r\"C:\\Users\\Sulakshana\\Desktop\\STUDY\\Course Work\\thesis project\\SER\\audio_speech_actors_01-24\"\n",
    "file_extension = \".wav\" \n",
    "file_paths, labels = utils.walk_filter(input_dir,file_extension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zip at 0x1b4d5f9ce80>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip(file_paths, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files:  1440\n"
     ]
    }
   ],
   "source": [
    "window_len = 3.5\n",
    "augment_factor = 1\n",
    "sr = 16000\n",
    "\n",
    "n_samples = int(window_len * sr)\n",
    "mel_spec_list = []\n",
    "audio_list = []\n",
    "label_list = []\n",
    "egmap_list = []\n",
    "pitch_list = []\n",
    "print(\"Number of files: \",len(file_paths))\n",
    "for file,label in zip(file_paths,labels):\n",
    "    signal = utils.load_audio(file,sr=16000)\n",
    "    n_windows = int(signal.shape[0] // n_samples) * augment_factor\n",
    "    n_correct_windows = 0\n",
    "    # print(\"n_windows: \",n_windows)\n",
    "    for i in range(n_windows):\n",
    "        audio_frames = signal[ int(n_samples * i / augment_factor):int(n_samples * (1 + i / augment_factor))]\n",
    "        audio_list.append(audio_frames)\n",
    "        label_list.append(label)\n",
    "        mel_spec_list.append(utils.extract_mel_spectogram(audio_frames))\n",
    "        # pitch,egmaps= utils.extract_features_from_file(audio_frames)\n",
    "        # egmap_list.append(egmaps)\n",
    "        # pitch_list.append(pitch)\n",
    "\n",
    "\n",
    "\n",
    "audio_arr = np.array(audio_list)      \n",
    "label_arr = np.array(label_list) \n",
    "mel_spec_arr = np.array(mel_spec_list)\n",
    "# egmaps_arr = np.array(egmap_list)\n",
    "# pitch_arr = np.array(pitch_list)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((106,), (106, 348, 64, 1), (106, 348, 25), (106, 348))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_arr.shape,mel_spec_arr.shape#,egmaps_arr.shape,pitch_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mel = mel_spec_arr.squeeze()\n",
    "# pitch_arr_reshaped = pitch_arr[:,:,np.newaxis]\n",
    "# data_mel_pitch = np.concatenate((data_mel,pitch_arr_reshaped),axis =2 )\n",
    "# data_mel.shape,pitch_arr_reshaped.shape,data_mel_pitch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((850, 348, 64), (213, 348, 64), (850,))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_datapoints = data_mel.shape[0]\n",
    "indexes = np.random.permutation(number_of_datapoints)\n",
    "train_idx = indexes[:int(number_of_datapoints*0.8)]\n",
    "test_idx = indexes[int(number_of_datapoints*0.8):]\n",
    "train_data = data_mel[train_idx]\n",
    "test_data = data_mel[test_idx]\n",
    "label_train = label_arr[train_idx]\n",
    "label_test = label_arr[test_idx]\n",
    "train_data.shape,test_data.shape,label_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(213, 348, 64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC(gamma='auto')\n",
    "n_train =train_data.shape[0]\n",
    "n_test = test_data.shape[0]\n",
    "\n",
    "clf.fit(train_data.reshape(n_train,-1),label_train)\n",
    "y_pred = clf.predict(test_data.reshape(n_test,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38967136150234744"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y_pred == label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 6, 7, 8])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.125"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow\n",
    "from matplotlib.pyplot import specgram\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "# from keras.preprocessing.sequence import pad_sequences\n",
    "# from tensorflow import keras\n",
    "# import keras\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input, Flatten, Dropout, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras import optimizers\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(128, 5,padding='same',\n",
    "                 input_shape=(348,64)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(MaxPooling1D(pool_size=(8)))\n",
    "model.add(Conv1D(128, 5,padding='same',))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "opt = optimizers.RMSprop(learning_rate=0.00005, rho=0.9, epsilon=None, decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_14 (Conv1D)          (None, 348, 128)          41088     \n",
      "                                                                 \n",
      " activation_21 (Activation)  (None, 348, 128)          0         \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 348, 128)          0         \n",
      "                                                                 \n",
      " max_pooling1d_7 (MaxPooling  (None, 43, 128)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_15 (Conv1D)          (None, 43, 128)           82048     \n",
      "                                                                 \n",
      " activation_22 (Activation)  (None, 43, 128)           0         \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 43, 128)           0         \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 5504)              0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 10)                55050     \n",
      "                                                                 \n",
      " activation_23 (Activation)  (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 178,186\n",
      "Trainable params: 178,186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "54/54 [==============================] - 4s 52ms/step - loss: 2.6480 - accuracy: 0.1835 - val_loss: 2.5625 - val_accuracy: 0.2066\n",
      "Epoch 2/30\n",
      "54/54 [==============================] - 3s 48ms/step - loss: 1.9775 - accuracy: 0.2835 - val_loss: 1.9920 - val_accuracy: 0.2629\n",
      "Epoch 3/30\n",
      "54/54 [==============================] - 3s 47ms/step - loss: 1.8071 - accuracy: 0.3153 - val_loss: 1.8178 - val_accuracy: 0.3333\n",
      "Epoch 4/30\n",
      "54/54 [==============================] - 2s 46ms/step - loss: 1.6067 - accuracy: 0.3812 - val_loss: 1.7443 - val_accuracy: 0.3662\n",
      "Epoch 5/30\n",
      "54/54 [==============================] - 3s 62ms/step - loss: 1.4997 - accuracy: 0.4329 - val_loss: 1.7969 - val_accuracy: 0.2911\n",
      "Epoch 6/30\n",
      "54/54 [==============================] - 3s 61ms/step - loss: 1.3861 - accuracy: 0.4871 - val_loss: 1.7101 - val_accuracy: 0.3521\n",
      "Epoch 7/30\n",
      "54/54 [==============================] - 3s 59ms/step - loss: 1.3182 - accuracy: 0.5071 - val_loss: 1.6566 - val_accuracy: 0.4131\n",
      "Epoch 8/30\n",
      "54/54 [==============================] - 3s 62ms/step - loss: 1.2644 - accuracy: 0.5071 - val_loss: 1.7647 - val_accuracy: 0.3380\n",
      "Epoch 9/30\n",
      "54/54 [==============================] - 3s 64ms/step - loss: 1.1969 - accuracy: 0.5647 - val_loss: 1.5164 - val_accuracy: 0.4178\n",
      "Epoch 10/30\n",
      "54/54 [==============================] - 3s 62ms/step - loss: 1.1396 - accuracy: 0.5894 - val_loss: 1.6321 - val_accuracy: 0.4225\n",
      "Epoch 11/30\n",
      "54/54 [==============================] - 3s 57ms/step - loss: 1.0889 - accuracy: 0.6176 - val_loss: 1.6126 - val_accuracy: 0.3803\n",
      "Epoch 12/30\n",
      "54/54 [==============================] - 3s 62ms/step - loss: 1.0211 - accuracy: 0.6353 - val_loss: 1.4231 - val_accuracy: 0.4977\n",
      "Epoch 13/30\n",
      "54/54 [==============================] - 3s 59ms/step - loss: 0.9833 - accuracy: 0.6706 - val_loss: 1.5800 - val_accuracy: 0.4319\n",
      "Epoch 14/30\n",
      "54/54 [==============================] - 3s 58ms/step - loss: 0.9349 - accuracy: 0.6718 - val_loss: 1.4989 - val_accuracy: 0.4789\n",
      "Epoch 15/30\n",
      "54/54 [==============================] - 3s 62ms/step - loss: 0.9032 - accuracy: 0.6847 - val_loss: 1.5016 - val_accuracy: 0.4460\n",
      "Epoch 16/30\n",
      "54/54 [==============================] - 3s 62ms/step - loss: 0.8728 - accuracy: 0.6976 - val_loss: 1.6148 - val_accuracy: 0.4366\n",
      "Epoch 17/30\n",
      "54/54 [==============================] - 3s 59ms/step - loss: 0.8268 - accuracy: 0.7153 - val_loss: 1.6692 - val_accuracy: 0.4460\n",
      "Epoch 18/30\n",
      "54/54 [==============================] - 3s 58ms/step - loss: 0.7878 - accuracy: 0.7329 - val_loss: 1.4363 - val_accuracy: 0.4413\n",
      "Epoch 19/30\n",
      "54/54 [==============================] - 3s 62ms/step - loss: 0.7567 - accuracy: 0.7482 - val_loss: 1.5093 - val_accuracy: 0.4695\n",
      "Epoch 20/30\n",
      "54/54 [==============================] - 3s 59ms/step - loss: 0.7251 - accuracy: 0.7765 - val_loss: 1.3642 - val_accuracy: 0.4883\n",
      "Epoch 21/30\n",
      "54/54 [==============================] - 3s 57ms/step - loss: 0.6789 - accuracy: 0.7882 - val_loss: 1.3301 - val_accuracy: 0.5258\n",
      "Epoch 22/30\n",
      "54/54 [==============================] - 3s 61ms/step - loss: 0.6502 - accuracy: 0.8024 - val_loss: 1.3244 - val_accuracy: 0.5211\n",
      "Epoch 23/30\n",
      "54/54 [==============================] - 3s 60ms/step - loss: 0.6218 - accuracy: 0.8294 - val_loss: 1.7870 - val_accuracy: 0.3615\n",
      "Epoch 24/30\n",
      "54/54 [==============================] - 3s 59ms/step - loss: 0.6056 - accuracy: 0.8212 - val_loss: 1.3095 - val_accuracy: 0.5258\n",
      "Epoch 25/30\n",
      "54/54 [==============================] - 3s 61ms/step - loss: 0.5872 - accuracy: 0.8176 - val_loss: 1.2534 - val_accuracy: 0.5681\n",
      "Epoch 26/30\n",
      "54/54 [==============================] - 3s 58ms/step - loss: 0.5242 - accuracy: 0.8447 - val_loss: 1.5813 - val_accuracy: 0.4272\n",
      "Epoch 27/30\n",
      "54/54 [==============================] - 4s 75ms/step - loss: 0.5153 - accuracy: 0.8459 - val_loss: 1.4700 - val_accuracy: 0.4413\n",
      "Epoch 28/30\n",
      "54/54 [==============================] - 3s 63ms/step - loss: 0.4973 - accuracy: 0.8506 - val_loss: 1.2936 - val_accuracy: 0.5681\n",
      "Epoch 29/30\n",
      "54/54 [==============================] - 3s 63ms/step - loss: 0.4953 - accuracy: 0.8459 - val_loss: 1.3561 - val_accuracy: 0.4930\n",
      "Epoch 30/30\n",
      "54/54 [==============================] - 4s 70ms/step - loss: 0.4558 - accuracy: 0.8659 - val_loss: 1.2500 - val_accuracy: 0.5540\n"
     ]
    }
   ],
   "source": [
    "cnnhistory=model.fit(train_data, label_train, batch_size=16, epochs=30, validation_data=(test_data, label_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('emotech')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "83db71e5b904faf0d9b882818f22b32414ba73fbc99f4ce5a2b4f5d0cff71fd4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
